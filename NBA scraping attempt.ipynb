{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libraries\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is copied from \n",
    "#https://medium.com/analytics-vidhya/intro-to-scraping-basketball-reference-data-8adcaa79664a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libraries\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "# create a function to scrape team performance for multiple years\n",
    "def scrape_NBA_team_data(years = [2017, 2018]):\n",
    "    \n",
    "    final_df = pd.DataFrame(columns = [\"Year\", \"Team\", \"W\", \"L\",\n",
    "                                       \"W/L%\", \"GB\", \"PS/G\", \"PA/G\",\n",
    "                                       \"SRS\", \"Playoffs\",\n",
    "                                       \"Losing_season\"])\n",
    "    \n",
    "    # loop through each year\n",
    "    for y in years:\n",
    "        # NBA season to scrape\n",
    "        year = y\n",
    "        \n",
    "        # URL to scrape, notice f string:\n",
    "        url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_standings.html\"\n",
    "        \n",
    "        # collect HTML data\n",
    "        html = urlopen(url)\n",
    "        \n",
    "        # create beautiful soup object from HTML\n",
    "        soup = BeautifulSoup(html, features=\"lxml\")\n",
    "        \n",
    "        # use getText()to extract the headers into a list\n",
    "        titles = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
    "        \n",
    "        # first, find only column headers\n",
    "        headers = titles[1:titles.index(\"SRS\")+1]\n",
    "        \n",
    "        # then, exclude first set of column headers (duplicated)\n",
    "        titles = titles[titles.index(\"SRS\")+1:]\n",
    "        \n",
    "        # next, row titles (ex: Boston Celtics, Toronto Raptors)\n",
    "        try:\n",
    "            row_titles = titles[0:titles.index(\"Eastern Conference\")]\n",
    "        except: row_titles = titles\n",
    "        # remove the non-teams from this list\n",
    "        for i in headers:\n",
    "            row_titles.remove(i)\n",
    "        row_titles.remove(\"Western Conference\")\n",
    "        divisions = [\"Atlantic Division\", \"Central Division\",\n",
    "                     \"Southeast Division\", \"Northwest Division\",\n",
    "                     \"Pacific Division\", \"Southwest Division\",\n",
    "                     \"Midwest Division\"]\n",
    "        for d in divisions:\n",
    "            try:\n",
    "                row_titles.remove(d)\n",
    "            except:\n",
    "                print(\"no division:\", d)\n",
    "        \n",
    "        # next, grab all data from rows (avoid first row)\n",
    "        rows = soup.findAll('tr')[1:]\n",
    "        team_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
    "                    for i in range(len(rows))]\n",
    "        # remove empty elements\n",
    "        team_stats = [e for e in team_stats if e != []]\n",
    "        # only keep needed rows\n",
    "        team_stats = team_stats[0:len(row_titles)]\n",
    "        \n",
    "        # add team name to each row in team_stats\n",
    "        for i in range(0, len(team_stats)):\n",
    "            team_stats[i].insert(0, row_titles[i])\n",
    "            team_stats[i].insert(0, year)\n",
    "            \n",
    "        # add team, year columns to headers\n",
    "        headers.insert(0, \"Team\")\n",
    "        headers.insert(0, \"Year\")\n",
    "        \n",
    "        # create a dataframe with all aquired info\n",
    "        year_standings = pd.DataFrame(team_stats, columns = headers)\n",
    "        \n",
    "        # add a column to dataframe to indicate playoff appearance\n",
    "        year_standings[\"Playoffs\"] = [\"Y\" if \"*\" in ele else \"N\" for ele in year_standings[\"Team\"]]\n",
    "        # remove * from team names\n",
    "        year_standings[\"Team\"] = [ele.replace('*', '') for ele in year_standings[\"Team\"]]\n",
    "        # add losing season indicator (win % < .5)\n",
    "        year_standings[\"Losing_season\"] = [\"Y\" if float(ele) < .5 else \"N\" for ele in year_standings[\"W/L%\"]]\n",
    "        \n",
    "        # append new dataframe to final_df\n",
    "        final_df = final_df.append(year_standings)\n",
    "        \n",
    "    # print final_df\n",
    "    print(final_df.info)\n",
    "    # export to csv\n",
    "    final_df.to_csv(\"nba_team_data.csv\", index=False)\n",
    "Test it on the last 30 se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to scrape team performance for multiple years\n",
    "\n",
    "def scrape_NBA_team_data(years = [2017, 2018],teams=['ATL','OKC']):\n",
    "    ##my columns will be ['Team','Year','Salary Cap','Wins_total','Wins_reg','Wins_play','Losses','W/L%','PS/G','PA/G','Salary','Sal%/C','1P_%TS','1P_%SC','2P_%TS','2P_%SC','3P_%TS','3P_%SC','4P_%TS','4P_%SC','5P_%TS','5P_%SC','6P_%TS','6P_%SC','7P_%TS','7P_%SC','8P_%TS','8P_%SC','9P_%TS','9P_%SC','10P_%TS','10P_%SC']\n",
    "        \n",
    "    final_df = pd.DataFrame(columns = [\"Year\", \"Team\", \"W\", \"L\",\n",
    "                                       \"W/L%\", \"GB\", \"PS/G\", \"PA/G\",\n",
    "                                       \"SRS\"])\n",
    "\n",
    "    # loop through each year\n",
    "    for y in years:\n",
    "        for t in teams:\n",
    "            team = t\n",
    "            \n",
    "        # NBA season to scrape\n",
    "            year = y\n",
    "\n",
    "\n",
    "\n",
    "            # URL to scrape, notice f string:\n",
    "            #url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_standings.html\"\n",
    "\n",
    "            team_url = f\"https://www.basketball-reference.com/teams/{team}/{year}.html\"\n",
    "\n",
    "\n",
    "            # collect HTML data\n",
    "            #html = urlopen(url)\n",
    "\n",
    "            team_html = urlopen(team_url)\n",
    "\n",
    "            # create beautiful soup object from HTML\n",
    "            #soup = BeautifulSoup(html, features=\"lxml\")\n",
    "\n",
    "            team_soup = BeautifulSoup(team_html,features='lxml')\n",
    "\n",
    "\n",
    "            # use getText()to extract the headers into a list\n",
    "            titles = [th.getText() for th in team_soup.findAll('tr', limit=2)[0].findAll('th')]\n",
    "\n",
    "            # first, find only column headers\n",
    "            headers = titles[titles.index(\"Salary\")]\n",
    "\n",
    "            # then, exclude first set of column headers (duplicated)\n",
    "           # titles = titles[titles.index(\"SRS\")+1:]\n",
    "\n",
    "            # next, grab all data from rows (avoid first row)\n",
    "            rows = team_soup.findAll('tr')[1:]\n",
    "            team_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
    "                        for i in range(len(rows))]\n",
    "            # remove empty elements\n",
    "            team_stats = [e for e in team_stats if e != []]\n",
    "            # only keep needed rows\n",
    "            team_stats = team_stats[0:len(row_titles)]\n",
    "\n",
    "            # add team name to each row in team_stats\n",
    "            for i in range(0, len(team_stats)):\n",
    "                team_stats[i].insert(0, row_titles[i])\n",
    "                team_stats[i].insert(0, year)\n",
    "\n",
    "            # add team, year columns to headers\n",
    "            headers.insert(0, \"Team\")\n",
    "            headers.insert(0, \"Year\")\n",
    "\n",
    "            # create a dataframe with all aquired info\n",
    "            year_standings = pd.DataFrame(team_stats, columns = headers)\n",
    "\n",
    "            # add a column to dataframe to indicate playoff appearance\n",
    "            #year_standings[\"Playoffs\"] = [\"Y\" if \"*\" in ele else \"N\" for ele in year_standings[\"Team\"]]\n",
    "            # remove * from team names\n",
    "            year_standings[\"Team\"] = [ele.replace('*', '') for ele in year_standings[\"Team\"]]\n",
    "            # add losing season indicator (win % < .5)\n",
    "            #year_standings[\"Losing_season\"] = [\"Y\" if float(ele) < .5 else \"N\" for ele in year_standings[\"W/L%\"]]\n",
    "\n",
    "            # append new dataframe to final_df\n",
    "            final_df = final_df.append(year_standings)\n",
    "\n",
    "        # print final_df\n",
    "        print(final_df.info)\n",
    "        # export to csv\n",
    "        final_df.to_csv(\"nba_team_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'Salary' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-a2fecd1e240f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m scrape_NBA_team_data(years = [1990, 1991, 1992, 1993, 1994,\n\u001b[0m\u001b[1;32m      2\u001b[0m                               \u001b[0;36m1995\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1996\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1997\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1998\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1999\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2002\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2003\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2004\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                               \u001b[0;36m2005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2006\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2007\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2008\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2009\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                               \u001b[0;36m2010\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2011\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2012\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2013\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2014\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-e4ee11ea0517>\u001b[0m in \u001b[0;36mscrape_NBA_team_data\u001b[0;34m(years, teams)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m# first, find only column headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtitles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Salary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m# then, exclude first set of column headers (duplicated)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'Salary' is not in list"
     ]
    }
   ],
   "source": [
    "scrape_NBA_team_data(years = [1990, 1991, 1992, 1993, 1994,\n",
    "                              1995, 1996, 1997, 1998, 1999,\n",
    "                              2000, 2001, 2002, 2003, 2004,\n",
    "                              2005, 2006, 2007, 2008, 2009,\n",
    "                              2010, 2011, 2012, 2013, 2014,\n",
    "                              2015, 2016, 2017, 2018, 2019,\n",
    "                              2020], \n",
    "                     teams = ['ATL','BOS','CHA','CHI',\n",
    "                                'CLE','DAL','DEN','DET',\n",
    "                                'GSW','HOU','IND','LAC',\n",
    "                                'LAL','MEM','MIA','MIL',\n",
    "                                'MIN','NJN','NOH','NYK',\n",
    "                                'OKC','ORL','PHI','PHO',\n",
    "                                'POR','SAC','SAS','TOR','UTA','WAS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_team_data.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
